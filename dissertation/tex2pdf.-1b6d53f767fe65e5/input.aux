\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{introduction}{{1}{1}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Why Neural Networks?}{1}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Classes of audio features}{1}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Intuition}{1}{section*.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces The audio style transformer $T$\relax }}{2}{figure.caption.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Project Goals}{2}{section.1.1}\protected@file@percent }
\newlabel{project-goals}{{1.1}{2}{Project Goals}{section.1.1}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Preparation}{3}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{preparation}{{2}{3}{Preparation}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Starting Point}{3}{section.2.1}\protected@file@percent }
\newlabel{starting-point}{{2.1}{3}{Starting Point}{section.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Machine Learning and Neural Networks}{3}{section.2.2}\protected@file@percent }
\newlabel{machine-learning-and-neural-networks}{{2.2}{3}{Machine Learning and Neural Networks}{section.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces \relax }}{4}{figure.caption.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Neural Networks}{4}{subsection.2.2.1}\protected@file@percent }
\newlabel{neural-networks}{{2.2.1}{4}{Neural Networks}{subsection.2.2.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Activation Functions}{4}{section*.6}\protected@file@percent }
\newlabel{eq:sigmoid}{{2.1}{5}{Activation Functions}{equation.2.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Loss Functions}{5}{subsection.2.2.2}\protected@file@percent }
\newlabel{loss-functions}{{2.2.2}{5}{Loss Functions}{subsection.2.2.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Mean Squared Error (MSE)}{5}{section*.7}\protected@file@percent }
\newlabel{eq:mse}{{2.3}{5}{Mean Squared Error (MSE)}{equation.2.2.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Negative Log Likelihood (NLL)}{5}{section*.8}\protected@file@percent }
\newlabel{eq:nllprod}{{2.5}{5}{Negative Log Likelihood (NLL)}{equation.2.2.5}{}}
\newlabel{eq:nll1}{{2.8}{6}{Negative Log Likelihood (NLL)}{equation.2.2.8}{}}
\newlabel{eq:nll2}{{2.9}{6}{Negative Log Likelihood (NLL)}{equation.2.2.9}{}}
\@writefile{toc}{\contentsline {paragraph}{Cross Entropy Loss}{6}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Optimization}{6}{subsection.2.2.3}\protected@file@percent }
\newlabel{optimization}{{2.2.3}{6}{Optimization}{subsection.2.2.3}{}}
\newlabel{eq:opt}{{2.10}{6}{Optimization}{equation.2.2.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Back-propagation}{7}{subsection.2.2.4}\protected@file@percent }
\newlabel{back-propagation}{{2.2.4}{7}{Back-propagation}{subsection.2.2.4}{}}
\newlabel{eq:grad}{{2.13}{7}{Back-propagation}{equation.2.2.13}{}}
\new