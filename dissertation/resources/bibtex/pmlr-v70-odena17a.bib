
@InProceedings{pmlr-v70-odena17a,
  title = 	 {Conditional Image Synthesis with Auxiliary Classifier {GAN}s},
  author = 	 {Augustus Odena and Christopher Olah and Jonathon Shlens},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {2642--2651},
  year = 	 {2017},
  editor = 	 {Doina Precup and Yee Whye Teh},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {International Convention Centre, Sydney, Australia},
  month = 	 {06--11 Aug},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/odena17a/odena17a.pdf},
  url = 	 {http://proceedings.mlr.press/v70/odena17a.html},
  abstract = 	 {In this paper we introduce new methods for the improved training of generative adversarial networks (GANs) for image synthesis. We construct a variant of GANs employing label conditioning that results in $128\times 128$ resolution image samples exhibiting global coherence. We expand on previous work for image quality assessment to provide two new analyses for assessing the discriminability and diversity of samples from class-conditional image synthesis models. These analyses demonstrate that high resolution samples provide class information not present in low resolution samples. Across 1000 ImageNet classes, $128\times 128$ samples are more than twice as discriminable as artificially resized $32\times 32$ samples. In addition, 84.7\% of the classes have samples exhibiting diversity comparable to real ImageNet data.}
}
