\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{introduction}{{1}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Project Goals}{1}{subsection.1.1}\protected@file@percent }
\newlabel{project-goals}{{1.1}{1}{Project Goals}{subsection.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Preparation}{1}{section.2}\protected@file@percent }
\newlabel{preparation}{{2}{1}{Preparation}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Starting Point}{1}{subsection.2.1}\protected@file@percent }
\newlabel{starting-point}{{2.1}{1}{Starting Point}{subsection.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Neural Networks}{2}{subsection.2.2}\protected@file@percent }
\newlabel{neural-networks}{{2.2}{2}{Neural Networks}{subsection.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Machine Learning Approaches for Cancer Detection - Scientific Figure on ResearchGate. Available from: https://www.researchgate.net/figure/Simple-Neural-Network-Model-Representation\_fig1\_324592713 [accessed 8 May, 2019]}}{2}{figure.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Convolutional Neural Networks}{2}{subsubsection.2.2.1}\protected@file@percent }
\newlabel{convolutional-neural-networks}{{2.2.1}{2}{Convolutional Neural Networks}{subsubsection.2.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Example of a 2D Convolution function, with (a) as input, (b) as the filter, and (c) as the output. For each output channel there exists a filter with different parameters (\texttt  {num\_out\_channel} = \texttt  {num\_filters}). Therefore we can consider all Convolutional layer as fully connected in the channel dimension (given we do not group filters).}}{2}{figure.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035}}{3}{figure.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Residual Neural Networks}{3}{subsubsection.2.2.2}\protected@file@percent }
\newlabel{residual-neural-networks}{{2.2.2}{3}{Residual Neural Networks}{subsubsection.2.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Style Transfer using Neural Networks}{3}{subsection.2.3}\protected@file@percent }
\newlabel{style-transfer-using-neural-networks}{{2.3}{3}{Style Transfer using Neural Networks}{subsection.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}GAN Style Transfers}{4}{subsection.2.4}\protected@file@percent }
\newlabel{gan-style-transfers}{{2.4}{4}{GAN Style Transfers}{subsection.2.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Generative Adversarial Networks}{4}{subsubsection.2.4.1}\protected@file@percent }
\newlabel{generative-adversarial-networks}{{2.4.1}{4}{Generative Adversarial Networks}{subsubsection.2.4.1}{}}
\newlabel{eq:gan}{{3}{4}{Generative Adversarial Networks}{equation.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}\texttt  {pix2pix}}{5}{subsubsection.2.4.2}\protected@file@percent }
\newlabel{pix2pix}{{2.4.2}{5}{\texorpdfstring {\texttt {pix2pix}}{pix2pix}}{subsubsection.2.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \texttt  {pix2pix} model dataflow. Each $\mathcal  {L}$ is a loss value calculated by computing the mean squared error between the discriminator output and the correct label. }}{5}{figure.4}\protected@file@percent }
\newlabel{fig:pix2pix}{{4}{5}{\texttt {pix2pix} model dataflow. Each $\mathcal {L}$ is a loss value calculated by computing the mean squared error between the discriminator output and the correct label}{figure.4}{}}
\newlabel{eq:pix2pix}{{4}{5}{\texorpdfstring {\texttt {pix2pix}}{pix2pix}}{equation.2.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Dataflow of CycleGAN architecture. $G_{A \rightarrow B} = G$ and $G_{B \rightarrow A} = F$ from equations \ref  {eq:cyclegan_1} and \ref  {eq:cyclegan_2}. }}{6}{figure.5}\protected@file@percent }
\newlabel{fig:cyclegan}{{5}{6}{Dataflow of CycleGAN architecture. $G_{A \rightarrow B} = G$ and $G_{B \rightarrow A} = F$ from equations \ref {eq:cyclegan_1} and \ref {eq:cyclegan_2}}{figure.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.3}CycleGAN}{6}{subsubsection.2.4.3}\protected@file@percent }
\newlabel{cyclegan}{{2.4.3}{6}{CycleGAN}{subsubsection.2.4.3}{}}
\newlabel{eq:cyclegan_1}{{5}{6}{CycleGAN}{equation.2.5}{}}
\newlabel{eq:cyclegan_2}{{6}{6}{CycleGAN}{equation.2.6}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.3.1}Cycle Consistency}{7}{paragraph.2.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.3.2}Total Loss}{7}{paragraph.2.4.3.2}\protected@file@percent }
\newlabel{eq:cyclegan_total}{{8}{7}{Total Loss}{equation.2.8}{}}
\newlabel{identity-loss}{{2.4.3.3}{7}{Identity Loss}{paragraph.2.4.3.3}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.3.3}Identity Loss }{7}{paragraph.2.4.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Audio Signal Processing Using Neural Networks}{7}{subsection.2.5}\protected@file@percent }
\newlabel{audio-signal-processing-using-neural-networks}{{2.5}{7}{Audio Signal Processing Using Neural Networks}{subsection.2.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1}Data Representations}{8}{subsubsection.2.5.1}\protected@file@percent }
\newlabel{data-representations}{{2.5.1}{8}{Data Representations}{subsubsection.2.5.1}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.5.1.1}Short Time Fourier Transform}{8}{paragraph.2.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{\numberline {2.5.1.1.1}Griffin-Lim}{8}{subparagraph.2.5.1.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.5.1.2}Constant-Q Transform}{8}{paragraph.2.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.5.1.3}STFT vs CQT}{8}{paragraph.2.5.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.5.1.4}Raw audio vs Time-Frequency Analyses}{9}{paragraph.2.5.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.5.1.5}Mel Frequency Scale}{9}{paragraph.2.5.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.2}WaveNet}{9}{subsubsection.2.5.2}\protected@file@percent }
\newlabel{wavenet}{{2.5.2}{9}{WaveNet}{subsubsection.2.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces A variant of WaveNet Architecture, implemented by Nvidia}}{9}{figure.6}\protected@file@percent }
\newlabel{fig:wavenet}{{6}{9}{A variant of WaveNet Architecture, implemented by Nvidia}{figure.6}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.5.2.1}Quantization}{10}{paragraph.2.5.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces A diagram of a causal convolutional network.}}{10}{figure.7}\protected@file@percent }
\newlabel{fig:causal_conv}{{7}{10}{A diagram of a causal convolutional network}{figure.7}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.5.2.2}Causal Co